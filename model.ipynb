{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jaguar Re-Identification\n",
        "\n",
        "## Score: .752"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIG\n",
        "# =============================================================================\n",
        "BASE_DIR = Path.cwd()  \n",
        "MODELS_DIR = BASE_DIR.parent / 'MODELS'\n",
        "CONVNEXT_DIR = MODELS_DIR / 'convnext-tensorflow2-large-21k-1k-384-fe-v1'\n",
        "EVA02_DIR = MODELS_DIR / 'eva02-pytorch-default-v1'\n",
        "\n",
        "class CFG:\n",
        "    # data\n",
        "    data_dir = BASE_DIR / 'jaguar-re-id'\n",
        "    train_csv = data_dir / 'train.csv'\n",
        "    test_csv = data_dir / 'test.csv'\n",
        "    train_dir = data_dir / 'train' / 'train'\n",
        "    test_dir = data_dir / 'test' / 'test'\n",
        "\n",
        "    # model backbones / weights roots (not all are used at once)\n",
        "    models_dir = MODELS_DIR\n",
        "    convnext_dir = CONVNEXT_DIR\n",
        "    eva02_dir = EVA02_DIR\n",
        "\n",
        "    backbone = 'convnext_large.fb_in22k_ft_in1k'\n",
        "    image_size = 224\n",
        "    num_classes = 31\n",
        "\n",
        "    epochs = 8\n",
        "    batch_size = 8\n",
        "    grad_accum_steps = 4\n",
        "    lr = 2e-4\n",
        "    weight_decay = 0.01\n",
        "    warmup_epochs = 1\n",
        "    \n",
        "    arcface_s = 30.0\n",
        "    arcface_m = 0.5\n",
        "    arcface_subcenters = 3\n",
        "    label_smoothing = 0.1\n",
        "    \n",
        "    samples_per_class = 60\n",
        "    val_split_seed = 42\n",
        "    early_stop_patience = 3\n",
        "\n",
        "    use_tta = True\n",
        "    use_multiscale_tta = True\n",
        "    multiscale_sizes = (224, 384)\n",
        "    use_qe = True\n",
        "    qe_top_k = 3\n",
        "    qe_weighted = True\n",
        "    use_rerank = True\n",
        "    rerank_lambda = 0.3\n",
        "    \n",
        "    train_seeds = [42, 420, 666]\n",
        "\n",
        "    do_pl = True\n",
        "    pl_threshold = 0.90\n",
        "    pl_max_add = 500\n",
        "    pl_epochs = 3\n",
        "    pl_lr = 1e-5\n",
        "\n",
        "    use_supcon = False\n",
        "    use_triplet = False\n",
        "    triplet_margin = 0.2\n",
        "    supcon_tau = 0.07\n",
        "    pk_p = 8\n",
        "    pk_k = 4\n",
        "\n",
        "    num_workers = 0\n",
        "    mixed_precision = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1833 | Val: 62 | Test pairs: 137270\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DATA\n",
        "# =============================================================================\n",
        "full_train = pd.read_csv(CFG.train_csv)\n",
        "test_df = pd.read_csv(CFG.test_csv)\n",
        "rng = random.Random(getattr(CFG, 'val_split_seed', 42))\n",
        "val_indices = []\n",
        "for gt, grp in full_train.groupby('ground_truth', sort=True):\n",
        "    idx = grp.index.tolist()\n",
        "    if len(idx) >= 2:\n",
        "        val_indices.extend(rng.sample(idx, 2))\n",
        "train_df = full_train.drop(index=val_indices).reset_index(drop=True)\n",
        "val_df = full_train.loc[val_indices].reset_index(drop=True)\n",
        "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test pairs: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRANSFORMS\n",
        "# =============================================================================\n",
        "NORM_MEAN, NORM_STD = ((0.481, 0.457, 0.408), (0.268, 0.261, 0.275)) if 'eva' in CFG.backbone else ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "        A.LongestMaxSize(max_size=CFG.image_size),\n",
        "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Affine(scale=(0.9, 1.1), rotate=(-12, 12), shear=(-8, 8), p=0.5),\n",
        "        A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1, p=0.6),\n",
        "        A.CoarseDropout(num_holes_range=(4, 12), hole_height_range=(16, 48), hole_width_range=(16, 48), p=0.3),\n",
        "        A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_test_transforms(flip=False, size=None):\n",
        "    sz = size if size is not None else CFG.image_size\n",
        "    t = [\n",
        "        A.LongestMaxSize(max_size=sz),\n",
        "        A.PadIfNeeded(sz, sz, border_mode=0),\n",
        "    ]\n",
        "    if flip:\n",
        "        t.append(A.HorizontalFlip(p=1.0))\n",
        "    t.extend([\n",
        "        A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    return A.Compose(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET & SAMPLER\n",
        "# =============================================================================\n",
        "class JaguarDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform, label_map=None, use_dir_col=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        self.use_dir_col = use_dir_col\n",
        "        if label_map is not None:\n",
        "            self.label_map = label_map\n",
        "        else:\n",
        "            unique_ids = sorted(df['ground_truth'].unique())\n",
        "            self.label_map = {name: i for i, name in enumerate(unique_ids)}\n",
        "        self.labels = [self.label_map[gt] for gt in df['ground_truth']]\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = Path(row['dir']) / row['filename'] if self.use_dir_col and 'dir' in row else self.img_dir / row['filename']\n",
        "        img = np.array(Image.open(img_path).convert('RGB'))\n",
        "        img = self.transform(image=img)['image']\n",
        "        return img, torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "\n",
        "class JaguarTestDataset(Dataset):\n",
        "    def __init__(self, filenames, img_dir, transform):\n",
        "        self.filenames = filenames\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.filenames[idx]\n",
        "        img = np.array(Image.open(self.img_dir / fname).convert('RGB'))\n",
        "        img = self.transform(image=img)['image']\n",
        "        return img, fname\n",
        "\n",
        "\n",
        "class BalancedSampler(Sampler):\n",
        "    def __init__(self, labels, samples_per_class):\n",
        "        self.labels = labels\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            self.class_indices[label].append(idx)\n",
        "        self.num_classes = len(self.class_indices)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        indices = []\n",
        "        for label in self.class_indices:\n",
        "            class_idx = self.class_indices[label]\n",
        "            if len(class_idx) >= self.samples_per_class:\n",
        "                sampled = random.sample(class_idx, self.samples_per_class)\n",
        "            else:\n",
        "                sampled = random.choices(class_idx, k=self.samples_per_class)\n",
        "            indices.extend(sampled)\n",
        "        random.shuffle(indices)\n",
        "        return iter(indices)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_classes * self.samples_per_class\n",
        "\n",
        "\n",
        "class PKSampler(Sampler):\n",
        "    def __init__(self, labels, p, k):\n",
        "        self.labels = np.asarray(labels)\n",
        "        self.p, self.k = p, k\n",
        "        self.class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            self.class_indices[label].append(idx)\n",
        "        self.classes = list(self.class_indices.keys())\n",
        "        n_samples = sum(len(v) for v in self.class_indices.values())\n",
        "        self.num_batches = max(1, n_samples // (p * k))\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.num_batches):\n",
        "            batch_classes = random.sample(self.classes, min(self.p, len(self.classes)))\n",
        "            indices = []\n",
        "            for c in batch_classes:\n",
        "                idx = self.class_indices[c]\n",
        "                if len(idx) >= self.k:\n",
        "                    indices.extend(random.sample(idx, self.k))\n",
        "                else:\n",
        "                    indices.extend(random.choices(idx, k=self.k))\n",
        "            random.shuffle(indices)\n",
        "            yield indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODEL\n",
        "# =============================================================================\n",
        "def supcon_loss(emb, labels, tau=0.07):\n",
        "    emb = F.normalize(emb.float(), dim=1)\n",
        "    sim = torch.mm(emb, emb.t()) / tau\n",
        "    B = emb.size(0)\n",
        "    eye = torch.eye(B, device=emb.device, dtype=torch.bool)\n",
        "    mask_same = (labels.unsqueeze(0) == labels.unsqueeze(1)) & ~eye\n",
        "    large_neg = -1e4\n",
        "    log_denom = torch.logsumexp(sim.masked_fill(eye, large_neg), dim=1)\n",
        "    log_num = torch.logsumexp(sim.masked_fill(~mask_same, large_neg), dim=1)\n",
        "    valid = mask_same.sum(1) > 0\n",
        "    if valid.sum() == 0:\n",
        "        return sim.sum() * 0\n",
        "    return (log_denom[valid] - log_num[valid]).mean()\n",
        "\n",
        "\n",
        "def triplet_loss(emb, labels, margin=0.2):\n",
        "    emb = F.normalize(emb.float(), dim=1)\n",
        "    sim = torch.mm(emb, emb.t())\n",
        "    B = emb.size(0)\n",
        "    eye = torch.eye(B, device=emb.device, dtype=torch.bool)\n",
        "    mask_pos = (labels.unsqueeze(0) == labels.unsqueeze(1)) & ~eye\n",
        "    mask_neg = labels.unsqueeze(0) != labels.unsqueeze(1)\n",
        "    sim_pos = sim.masked_fill(~mask_pos, -2.0)\n",
        "    sim_neg = sim.masked_fill(~mask_neg, -2.0)\n",
        "    sim_pos_max = sim_pos.max(1)[0]\n",
        "    sim_neg_max = sim_neg.max(1)[0]\n",
        "    valid = mask_pos.sum(1) > 0\n",
        "    if valid.sum() == 0:\n",
        "        return emb.sum() * 0\n",
        "    loss = (margin - sim_pos_max[valid] + sim_neg_max[valid]).clamp(min=0).mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1.0 / self.p)\n",
        "\n",
        "\n",
        "class ArcFaceLoss(nn.Module):\n",
        "    def __init__(self, in_features, num_classes, s=30.0, m=0.5):\n",
        "        super().__init__()\n",
        "        self.s, self.m = s, m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "    \n",
        "    def forward(self, x, labels):\n",
        "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
        "        theta = torch.acos(cosine.clamp(-1 + 1e-7, 1 - 1e-7))\n",
        "        target_logits = torch.cos(theta + self.m)\n",
        "        one_hot = F.one_hot(labels, num_classes=cosine.size(1)).float()\n",
        "        output = cosine * (1 - one_hot) + target_logits * one_hot\n",
        "        return output * self.s\n",
        "\n",
        "\n",
        "class SubCenterArcFaceLoss(nn.Module):\n",
        "    def __init__(self, in_features, num_classes, K=3, s=30.0, m=0.5):\n",
        "        super().__init__()\n",
        "        self.s, self.m, self.K = s, m, K\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(num_classes * K, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "    \n",
        "    def forward(self, x, labels):\n",
        "        x_n = F.normalize(x)\n",
        "        w_n = F.normalize(self.weight)\n",
        "        cosine = F.linear(x_n, w_n)\n",
        "        B, NK = cosine.shape\n",
        "        num_classes = NK // self.K\n",
        "        cosine = cosine.view(B, num_classes, self.K)\n",
        "        cosine_max, _ = cosine.max(dim=2)\n",
        "        theta_target = torch.acos(cosine_max[range(B), labels].clamp(-1 + 1e-7, 1 - 1e-7))\n",
        "        target_logits = torch.cos(theta_target + self.m)\n",
        "        one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
        "        output = cosine_max * (1 - one_hot) + target_logits.unsqueeze(1) * one_hot\n",
        "        return output * self.s\n",
        "\n",
        "\n",
        "class JaguarModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kwargs = {'pretrained': True, 'num_classes': 0}\n",
        "        if 'vit' in CFG.backbone or 'eva' in CFG.backbone:\n",
        "            kwargs['img_size'] = CFG.image_size\n",
        "        self.backbone = timm.create_model(CFG.backbone, **kwargs)\n",
        "        self.feat_dim = self.backbone.num_features\n",
        "        self.gem = GeM()\n",
        "        self.bn = nn.BatchNorm1d(self.feat_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        K = getattr(CFG, 'arcface_subcenters', 1)\n",
        "        if K > 1:\n",
        "            self.arcface = SubCenterArcFaceLoss(self.feat_dim, CFG.num_classes, K=K, s=CFG.arcface_s, m=CFG.arcface_m)\n",
        "        else:\n",
        "            self.arcface = ArcFaceLoss(self.feat_dim, CFG.num_classes, CFG.arcface_s, CFG.arcface_m)\n",
        "        print(f\"Loaded {CFG.backbone} | Features: {self.feat_dim}\")\n",
        "\n",
        "    def extract(self, x):\n",
        "        features = self.backbone.forward_features(x)\n",
        "        if features.dim() == 3:\n",
        "            B, N, C = features.shape\n",
        "            H = W = int(math.sqrt(N))\n",
        "            if H * W != N:\n",
        "                features = features[:, -H*W:, :]\n",
        "            features = features.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "            emb = self.gem(features).flatten(1)\n",
        "        else:\n",
        "            emb = self.gem(features).flatten(1)\n",
        "        emb = self.bn(emb)\n",
        "        return emb\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        emb = self.extract(x)\n",
        "        if labels is not None:\n",
        "            emb = self.dropout(emb)\n",
        "            return self.arcface(emb, labels)\n",
        "        return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# POST-PROCESSING\n",
        "# =============================================================================\n",
        "def query_expansion(emb, top_k=None, verbose=True):\n",
        "    top_k = top_k if top_k is not None else getattr(CFG, 'qe_top_k', 3)\n",
        "    weighted = getattr(CFG, 'qe_weighted', False)\n",
        "    if verbose:\n",
        "        print(\"Applying Query Expansion...\")\n",
        "    sims = emb @ emb.T\n",
        "    indices = np.argsort(-sims, axis=1)[:, :top_k]\n",
        "    new_emb = np.zeros_like(emb)\n",
        "    for i in range(len(emb)):\n",
        "        w = np.maximum(sims[i, indices[i]], 1e-8) if weighted else np.ones(top_k)\n",
        "        new_emb[i] = np.average(emb[indices[i]], axis=0, weights=w)\n",
        "    return new_emb / (np.linalg.norm(new_emb, axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "\n",
        "def k_reciprocal_rerank(prob, k1=20, k2=6, lambda_value=None, verbose=True):\n",
        "    lambda_value = lambda_value if lambda_value is not None else getattr(CFG, 'rerank_lambda', 0.3)\n",
        "    if verbose:\n",
        "        print(\"Applying Re-ranking...\")\n",
        "    q_g_dist = 1 - prob\n",
        "    original_dist = q_g_dist.copy()\n",
        "    initial_rank = np.argsort(original_dist, axis=1)\n",
        "    \n",
        "    nn_k1 = []\n",
        "    for i in range(prob.shape[0]):\n",
        "        forward_k1 = initial_rank[i, :k1+1]\n",
        "        backward_k1 = initial_rank[forward_k1, :k1+1]\n",
        "        fi = np.where(backward_k1 == i)[0]\n",
        "        nn_k1.append(forward_k1[fi])\n",
        "    \n",
        "    jaccard_dist = np.zeros_like(original_dist)\n",
        "    for i in range(prob.shape[0]):\n",
        "        ind_non_zero = np.where(original_dist[i, :] < 0.6)[0]\n",
        "        ind_images = [inv for inv in ind_non_zero if len(np.intersect1d(nn_k1[i], nn_k1[inv])) > 0]\n",
        "        for j in ind_images:\n",
        "            intersection = len(np.intersect1d(nn_k1[i], nn_k1[j]))\n",
        "            union = len(np.union1d(nn_k1[i], nn_k1[j]))\n",
        "            jaccard_dist[i, j] = 1 - intersection / union\n",
        "    \n",
        "    return 1 - (jaccard_dist * lambda_value + original_dist * (1 - lambda_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VALIDATION\n",
        "# =============================================================================\n",
        "def compute_val_mAP(emb, labels):\n",
        "    emb = np.asarray(emb)\n",
        "    labels = np.asarray(labels)\n",
        "    n = len(labels)\n",
        "    sim = emb @ emb.T\n",
        "    mAP_per_id = []\n",
        "    for c in np.unique(labels):\n",
        "        idx = np.where(labels == c)[0]\n",
        "        if len(idx) < 2:\n",
        "            continue\n",
        "        aps = []\n",
        "        for q in idx:\n",
        "            gallery = np.array([i for i in range(n) if i != q])\n",
        "            rel = (labels[gallery] == c).astype(float)\n",
        "            if rel.sum() == 0:\n",
        "                continue\n",
        "            order = np.argsort(-sim[q, gallery])\n",
        "            rel_ord = rel[order]\n",
        "            prec = np.cumsum(rel_ord) / (1 + np.arange(len(rel_ord)))\n",
        "            ap = (prec[rel_ord == 1].sum()) / rel.sum()\n",
        "            aps.append(ap)\n",
        "        if aps:\n",
        "            mAP_per_id.append(np.mean(aps))\n",
        "    return float(np.mean(mAP_per_id)) if mAP_per_id else 0.0\n",
        "\n",
        "def compute_val_mAP_from_sim(sim, labels):\n",
        "    labels = np.asarray(labels)\n",
        "    n = len(labels)\n",
        "    mAP_per_id = []\n",
        "    for c in np.unique(labels):\n",
        "        idx = np.where(labels == c)[0]\n",
        "        if len(idx) < 2:\n",
        "            continue\n",
        "        aps = []\n",
        "        for q in idx:\n",
        "            gallery = np.array([i for i in range(n) if i != q])\n",
        "            rel = (labels[gallery] == c).astype(float)\n",
        "            if rel.sum() == 0:\n",
        "                continue\n",
        "            order = np.argsort(-sim[q, gallery])\n",
        "            rel_ord = rel[order]\n",
        "            prec = np.cumsum(rel_ord) / (1 + np.arange(len(rel_ord)))\n",
        "            ap = (prec[rel_ord == 1].sum()) / rel.sum()\n",
        "            aps.append(ap)\n",
        "        if aps:\n",
        "            mAP_per_id.append(np.mean(aps))\n",
        "    return float(np.mean(mAP_per_id)) if mAP_per_id else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n",
            "--- Seed 42 ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a27a6ec65b7e4cfe9d4b939c7529c355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc8506e2f9f04b839ad41a52ce07f82b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 13.4106 | Val mAP: 0.5220 | LR: 1.92e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a13ddf0e34a4a418e72ab3d7abcb685",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00ad767ac4184695b5f4a2affc8a5600",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 5.5053 | Val mAP: 0.7859 | LR: 1.71e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e27087a25d3a4145a4c274781d585331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c62914000e54fa4be1a01ad08747862",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.4533 | Val mAP: 0.8585 | LR: 1.38e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acf424445fdf421e8e1e60b5112339fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6443e6cfd48140988ca0c8533ad944aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.6811 | Val mAP: 0.8476 | LR: 1.00e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92dd089d10bf4070999457ea593591d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3df2925bec84638be146e208030546f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.2573 | Val mAP: 0.8416 | LR: 6.17e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "124c96d7a5f9482d8cdc460ddb7cb21e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02b30f1ba8934a54a8b1f6eb270d302d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.0096 | Val mAP: 0.8538 | LR: 2.93e-05\n",
            "Early stop at epoch 6 (no val mAP improvement for 3 epochs)\n",
            "Seed 42 done | Best val mAP: 0.8585\n",
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n",
            "--- Seed 420 ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c41af86009d54e4e9d6f13aad912f179",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef52428622ea41f8affdd6321cf418e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 13.6120 | Val mAP: 0.4635 | LR: 1.92e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5378fe548e243998013421c846e3602",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a0510a5f2894c5aa9adcbae811322ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 5.8252 | Val mAP: 0.6428 | LR: 1.71e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c3c22cfb9e241eab3560ba775199a00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02483f8e1c2d4e95a7ec3f1d1dc51bc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.7620 | Val mAP: 0.6967 | LR: 1.38e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2337703803343f88517e65ad623ee24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2903c07dda26470a99c53d8613a9e6fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.8840 | Val mAP: 0.7485 | LR: 1.00e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9049f2795e543568e63f184eb06d08d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "254f851dd5034a08ba2ed2b83720328d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.2782 | Val mAP: 0.7684 | LR: 6.17e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "644d129f22894abf86cd7318954378c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef61ea88ad4e41bd91ad6707d6ee2d59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.1124 | Val mAP: 0.7804 | LR: 2.93e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f084117599c4416a294982e4bd4f3af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2983539a2964d70b6bcb65c93087098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 0.9624 | Val mAP: 0.7778 | LR: 7.61e-06\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbb2f778c878463c8626aa679a84d919",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81b8715487cc4e95b7219f3fb53e6f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 0.9058 | Val mAP: 0.7815 | LR: 0.00e+00\n",
            "Seed 420 done | Best val mAP: 0.7815\n",
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n",
            "--- Seed 666 ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4fd25d234dc4e6eb9884e393f4718d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff062d5818d14443b62606791ff365dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 13.1906 | Val mAP: 0.5428 | LR: 1.92e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76d43bcab37c46eb9c582b1ca6748d0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea518c7779264398b79a6cdb06a76934",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 5.5465 | Val mAP: 0.7966 | LR: 1.71e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff304cf1b8a44e11bec1a00b5578ce57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9f7d96d47af4263a40add6b1521bd35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.6900 | Val mAP: 0.8382 | LR: 1.38e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd0e36c3158643a384f37d564e4b6ca9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f6656a96cdd412ca90782c37ce23706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.6420 | Val mAP: 0.8635 | LR: 1.00e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2ab0d1e084b4989adc588d336e95131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dfda490075d42889b40a6694c8ffdf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.2709 | Val mAP: 0.8590 | LR: 6.17e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a4ee487af441acb58f03b4122cae21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4059647ac12e4d4ca007b552d478137b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.0075 | Val mAP: 0.8766 | LR: 2.93e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54072407821e48b5aeaa36a715d343d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cf6128f82b04ebbb9a70cd3e1d357ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 0.9205 | Val mAP: 0.8899 | LR: 7.61e-06\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df02e1a95d9d4eacb9a20b964a1ed8a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8/8:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5b04dd0ebc8463da1e020c75102ba40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 0.8890 | Val mAP: 0.8690 | LR: 0.00e+00\n",
            "Seed 666 done | Best val mAP: 0.8899\n",
            "Training complete | All seeds done.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TRAINING\n",
        "# =============================================================================\n",
        "train_dataset = JaguarDataset(train_df, CFG.train_dir, get_train_transforms())\n",
        "val_dataset = JaguarDataset(val_df, CFG.train_dir, get_test_transforms(flip=False))\n",
        "\n",
        "for seed in CFG.train_seeds:\n",
        "    seed_everything(seed)\n",
        "    if getattr(CFG, 'use_supcon', False) or getattr(CFG, 'use_triplet', False):\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_sampler=PKSampler(train_dataset.labels, CFG.pk_p, CFG.pk_k),\n",
        "            num_workers=CFG.num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    else:\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=CFG.batch_size,\n",
        "            sampler=BalancedSampler(train_dataset.labels, CFG.samples_per_class),\n",
        "            num_workers=CFG.num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "    grad_accum = getattr(CFG, 'grad_accum_steps', 1)\n",
        "\n",
        "    model = JaguarModel().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing)\n",
        "\n",
        "    best_val_mAP = 0.0\n",
        "    patience = getattr(CFG, 'early_stop_patience', 5)\n",
        "    no_improve = 0\n",
        "    print(f\"--- Seed {seed} ---\")\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
        "        optimizer.zero_grad()\n",
        "        for step, (imgs, labels) in enumerate(pbar):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                if getattr(CFG, 'use_supcon', False):\n",
        "                    emb = model(imgs)\n",
        "                    loss = supcon_loss(emb, labels, CFG.supcon_tau)\n",
        "                elif getattr(CFG, 'use_triplet', False):\n",
        "                    emb = model(imgs)\n",
        "                    loss = triplet_loss(emb, labels, getattr(CFG, 'triplet_margin', 0.2))\n",
        "                else:\n",
        "                    logits = model(imgs, labels)\n",
        "                    loss = criterion(logits, labels)\n",
        "                loss = loss / grad_accum\n",
        "            scaler.scale(loss).backward()\n",
        "            if (step + 1) % grad_accum == 0 or (step + 1) == len(train_loader):\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "            total_loss += loss.item() * grad_accum\n",
        "            pbar.set_postfix({'loss': f'{loss.item() * grad_accum:.4f}'})\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        emb_list, label_list = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in tqdm(val_loader, desc='Val', leave=False):\n",
        "                emb = model(imgs.to(device))\n",
        "                emb_list.append(F.normalize(emb, dim=1).cpu().numpy())\n",
        "                label_list.append(labels.numpy())\n",
        "        emb_val = np.concatenate(emb_list)\n",
        "        labels_val = np.concatenate(label_list)\n",
        "        val_mAP = compute_val_mAP(emb_val, labels_val)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val mAP: {val_mAP:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
        "        if val_mAP > best_val_mAP:\n",
        "            best_val_mAP = val_mAP\n",
        "            no_improve = 0\n",
        "            torch.save(model.state_dict(), f'best_model_seed{seed}.pth')\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(f\"Early stop at epoch {epoch+1} (no val mAP improvement for {patience} epochs)\")\n",
        "                break\n",
        "\n",
        "    print(f\"Seed {seed} done | Best val mAP: {best_val_mAP:.4f}\")\n",
        "\n",
        "print(\"Training complete | All seeds done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting embeddings for 371 images...\n",
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d61cc23a49cd44d9a48fd59f3137be8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL:   0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a39a418e02554d97a8f73cecb348b6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL:   0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02c4e3895ca842b0b2a5c27ef70623dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL:   0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded convnext_large.fb_in22k_ft_in1k | Features: 1536\n",
            "PL: 363 samples | FT 3 ep\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce704171c28a4cea9205127421d3d749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL ep 1:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f80c15b84b04633a78dd9f93ffea5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL ep 2:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8369b695c01447108971554aed2374b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "PL ep 3:   0%|          | 0/233 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PL done.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "288a133d39554258a7fb524cc84bbb19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02037ad34c1d4d87b247ba6aaf62e0be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e88cd6d11be44356a40b243fd52d77d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05c2481d40cd4be6b9fff99dd49fbb4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PL model.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# INFERENCE\n",
        "# =============================================================================\n",
        "unique_images = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
        "print(f\"Extracting embeddings for {len(unique_images)} images...\")\n",
        "\n",
        "def extract_embeddings(transform, m):\n",
        "    loader = DataLoader(JaguarTestDataset(unique_images, CFG.test_dir, transform), batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "    feats, names = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, fnames in tqdm(loader, leave=False):\n",
        "            emb = m(imgs.to(device))\n",
        "            feats.append(F.normalize(emb, dim=1).cpu())\n",
        "            names.extend(fnames)\n",
        "    return torch.cat(feats, dim=0), names\n",
        "\n",
        "def get_embeddings(m):\n",
        "    scales = getattr(CFG, 'multiscale_sizes', (CFG.image_size,)) if getattr(CFG, 'use_multiscale_tta', False) else (CFG.image_size,)\n",
        "    if 'eva' in CFG.backbone or 'vit' in CFG.backbone:\n",
        "        scales = tuple(s for s in scales if s <= CFG.image_size) or (CFG.image_size,)\n",
        "    embs = []\n",
        "    for sz in scales:\n",
        "        e1, names = extract_embeddings(get_test_transforms(flip=False, size=sz), m)\n",
        "        if CFG.use_tta:\n",
        "            e2, _ = extract_embeddings(get_test_transforms(flip=True, size=sz), m)\n",
        "            embs.append(F.normalize((e1 + e2) / 2, dim=1))\n",
        "        else:\n",
        "            embs.append(e1)\n",
        "    e = F.normalize(torch.stack(embs).mean(0), dim=1)\n",
        "    return e.numpy(), names\n",
        "\n",
        "pl_model = None\n",
        "if getattr(CFG, 'do_pl', False):\n",
        "    def _gen_pl(model, test_fnames, lm, inv_lm, thresh, max_add):\n",
        "        model.eval()\n",
        "        loader = DataLoader(JaguarTestDataset(test_fnames, CFG.test_dir, get_test_transforms(flip=False)), batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "        w = F.normalize(model.arcface.weight.data, dim=1)\n",
        "        K = getattr(CFG, 'arcface_subcenters', 1)\n",
        "        out = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, fnames in tqdm(loader, desc='PL'):\n",
        "                emb = F.normalize(model(imgs.to(device)), dim=1)\n",
        "                logits = emb @ w.T.cuda() * CFG.arcface_s\n",
        "                if K > 1:\n",
        "                    logits = logits.view(emb.size(0), CFG.num_classes, K).max(dim=2)[0]\n",
        "                probs = F.softmax(logits, dim=1)\n",
        "                mp, pi = probs.max(1)\n",
        "                for i, fn in enumerate(fnames):\n",
        "                    if mp[i].item() >= thresh:\n",
        "                        out.append({'filename': fn, 'ground_truth': inv_lm[pi[i].item()], 'dir': str(CFG.test_dir)})\n",
        "        pl_df = pd.DataFrame(out)\n",
        "        return pl_df.sample(n=min(len(pl_df), max_add), random_state=42) if len(pl_df) > max_add else pl_df\n",
        "    inv_lm = {v: k for k, v in train_dataset.label_map.items()}\n",
        "    tf = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
        "    pl_dfs = []\n",
        "    for seed in CFG.train_seeds:\n",
        "        ckpt = f'best_model_seed{seed}.pth'\n",
        "        if Path(ckpt).exists():\n",
        "            m = JaguarModel().to(device)\n",
        "            m.load_state_dict(torch.load(ckpt))\n",
        "            pl_dfs.append(_gen_pl(m, tf, train_dataset.label_map, inv_lm, CFG.pl_threshold, CFG.pl_max_add))\n",
        "            del m\n",
        "            torch.cuda.empty_cache()\n",
        "    if pl_dfs:\n",
        "        pl_df = pd.concat(pl_dfs).drop_duplicates(subset=['filename']).reset_index(drop=True)\n",
        "        if len(pl_df) > 0:\n",
        "            tr = train_df.copy()\n",
        "            tr['dir'] = str(CFG.train_dir)\n",
        "            comb = pd.concat([tr, pl_df], ignore_index=True)\n",
        "            ds = JaguarDataset(comb, CFG.train_dir, get_train_transforms(), label_map=train_dataset.label_map, use_dir_col=True)\n",
        "            ld = DataLoader(ds, batch_size=CFG.batch_size, sampler=BalancedSampler(ds.labels, CFG.samples_per_class), num_workers=CFG.num_workers, pin_memory=True)\n",
        "            pl_model = JaguarModel().to(device)\n",
        "            pl_model.load_state_dict(torch.load(f'best_model_seed{CFG.train_seeds[0]}.pth'))\n",
        "            opt = torch.optim.AdamW(pl_model.parameters(), lr=CFG.pl_lr, weight_decay=CFG.weight_decay)\n",
        "            sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.pl_epochs)\n",
        "            scal = torch.amp.GradScaler('cuda')\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing)\n",
        "            print(f\"PL: {len(pl_df)} samples | FT {CFG.pl_epochs} ep\")\n",
        "            for ep in range(CFG.pl_epochs):\n",
        "                pl_model.train()\n",
        "                opt.zero_grad()\n",
        "                for step, (imgs, labels) in enumerate(tqdm(ld, desc=f'PL ep {ep+1}')):\n",
        "                    imgs, labels = imgs.to(device), labels.to(device)\n",
        "                    with torch.amp.autocast('cuda'):\n",
        "                        loss = criterion(pl_model(imgs, labels), labels) / CFG.grad_accum_steps\n",
        "                    scal.scale(loss).backward()\n",
        "                    if (step + 1) % CFG.grad_accum_steps == 0 or (step + 1) == len(ld):\n",
        "                        scal.step(opt)\n",
        "                        scal.update()\n",
        "                        opt.zero_grad()\n",
        "                sch.step()\n",
        "            torch.save(pl_model.state_dict(), 'pl_model.pth')\n",
        "            print('PL done.')\n",
        "if pl_model is not None:\n",
        "    pl_model.eval()\n",
        "    emb, names = get_embeddings(pl_model)\n",
        "    emb = emb.astype(np.float32) / (np.linalg.norm(emb, axis=1, keepdims=True) + 1e-8)\n",
        "    print('Using PL model.')\n",
        "else:\n",
        "    emb_list = []\n",
        "    for seed in CFG.train_seeds:\n",
        "        ckpt_path = f'best_model_seed{seed}.pth'\n",
        "        if not Path(ckpt_path).exists():\n",
        "            raise FileNotFoundError(f\"Run training first; missing {ckpt_path}\")\n",
        "        model = JaguarModel().to(device)\n",
        "        model.load_state_dict(torch.load(ckpt_path))\n",
        "        model.eval()\n",
        "        e, names = get_embeddings(model)\n",
        "        emb_list.append(e)\n",
        "    emb = np.mean(emb_list, axis=0).astype(np.float32)\n",
        "    emb = emb / (np.linalg.norm(emb, axis=1, keepdims=True) + 1e-8)\n",
        "img_map = {n: i for i, n in enumerate(names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Query Expansion...\n",
            "Applying Re-ranking...\n",
            "Saved submission.csv | Mean sim: 0.4234\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SUBMISSION\n",
        "# =============================================================================\n",
        "if CFG.use_qe:\n",
        "    emb = query_expansion(emb)\n",
        "sim_matrix = emb @ emb.T\n",
        "if CFG.use_rerank:\n",
        "    sim_matrix = k_reciprocal_rerank(sim_matrix)\n",
        "preds = [float(np.clip(sim_matrix[img_map[row['query_image']], img_map[row['gallery_image']]], 0, 1)) for _, row in test_df.iterrows()]\n",
        "pd.DataFrame({'row_id': test_df['row_id'], 'similarity': preds}).to_csv('submission.csv', index=False)\n",
        "print(f\"Saved submission.csv | Mean sim: {np.mean(preds):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
