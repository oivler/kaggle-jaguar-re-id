{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaguar Re-Identification\n",
    "\n",
    "## Score: .859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIG\n",
    "# =============================================================================\n",
    "class CFG:\n",
    "    data_dir = Path('jaguar-re-id')\n",
    "    train_csv = data_dir / 'train.csv'\n",
    "    test_csv = data_dir / 'test.csv'\n",
    "    train_dir = data_dir / 'train' / 'train'\n",
    "    test_dir = data_dir / 'test' / 'test'\n",
    "    \n",
    "    backbone = 'eva02_base_patch14_448.mim_in22k_ft_in22k_in1k'\n",
    "    image_size = 448\n",
    "    num_classes = 31\n",
    "    \n",
    "    epochs = 10\n",
    "    batch_size = 4\n",
    "    grad_accum = 4\n",
    "    lr = 2e-5\n",
    "    weight_decay = 1e-3\n",
    "    \n",
    "    arcface_s = 30.0\n",
    "    arcface_m = 0.5\n",
    "    \n",
    "    use_tta = True\n",
    "    use_qe = True\n",
    "    use_rerank = True\n",
    "    \n",
    "    num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1895 | Test pairs: 137270\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA\n",
    "# =============================================================================\n",
    "train_df = pd.read_csv(CFG.train_csv)\n",
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Train: {len(train_df)} | Test pairs: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRANSFORMS\n",
    "# =============================================================================\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((CFG.image_size, CFG.image_size)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.481, 0.457, 0.408], [0.268, 0.261, 0.275]),\n",
    "    T.RandomErasing(p=0.25),\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize((CFG.image_size, CFG.image_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.481, 0.457, 0.408], [0.268, 0.261, 0.275]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET\n",
    "# =============================================================================\n",
    "class JaguarDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        if not is_test:\n",
    "            unique_ids = sorted(df['ground_truth'].unique())\n",
    "            self.label_map = {name: i for i, name in enumerate(unique_ids)}\n",
    "            self.df['label'] = self.df['ground_truth'].map(self.label_map)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.img_dir / row['filename']).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        if self.is_test:\n",
    "            return img, row['filename']\n",
    "        return img, torch.tensor(row['label'], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL\n",
    "# =============================================================================\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1.0 / self.p)\n",
    "\n",
    "\n",
    "class ArcFaceLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s, self.m = s, m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, x, label=None):\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        if label is None:\n",
    "            return cosine\n",
    "        phi = cosine - self.m\n",
    "        one_hot = torch.zeros_like(cosine).scatter_(1, label.view(-1, 1), 1)\n",
    "        return ((one_hot * phi) + ((1.0 - one_hot) * cosine)) * self.s\n",
    "\n",
    "\n",
    "class JaguarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(CFG.backbone, pretrained=True, num_classes=0)\n",
    "        self.feat_dim = self.backbone.num_features\n",
    "        self.gem = GeM()\n",
    "        self.bn = nn.BatchNorm1d(self.feat_dim)\n",
    "        self.head = ArcFaceLayer(self.feat_dim, CFG.num_classes, CFG.arcface_s, CFG.arcface_m)\n",
    "        print(f\"Loaded {CFG.backbone} | Feat: {self.feat_dim}\")\n",
    "    \n",
    "    def forward(self, x, label=None):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        if features.dim() == 3:\n",
    "            B, N, C = features.shape\n",
    "            H = W = int(math.sqrt(N))\n",
    "            if H * W != N:\n",
    "                features = features[:, -H*W:, :]\n",
    "            features = features.permute(0, 2, 1).reshape(B, C, H, W)\n",
    "        emb = self.gem(features).flatten(1)\n",
    "        emb = self.bn(emb)\n",
    "        if label is not None:\n",
    "            return self.head(emb, label)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# POST-PROCESSING\n",
    "# =============================================================================\n",
    "def query_expansion(emb, top_k=3):\n",
    "    print(\"Applying Query Expansion...\")\n",
    "    sims = emb @ emb.T\n",
    "    indices = np.argsort(-sims, axis=1)[:, :top_k]\n",
    "    new_emb = np.zeros_like(emb)\n",
    "    for i in range(len(emb)):\n",
    "        new_emb[i] = np.mean(emb[indices[i]], axis=0)\n",
    "    return new_emb / np.linalg.norm(new_emb, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def k_reciprocal_rerank(prob, k1=20, k2=6, lambda_value=0.3):\n",
    "    print(\"Applying Re-ranking...\")\n",
    "    q_g_dist = 1 - prob\n",
    "    original_dist = q_g_dist.copy()\n",
    "    initial_rank = np.argsort(original_dist, axis=1)\n",
    "    \n",
    "    nn_k1 = []\n",
    "    for i in range(prob.shape[0]):\n",
    "        forward_k1 = initial_rank[i, :k1+1]\n",
    "        backward_k1 = initial_rank[forward_k1, :k1+1]\n",
    "        fi = np.where(backward_k1 == i)[0]\n",
    "        nn_k1.append(forward_k1[fi])\n",
    "    \n",
    "    jaccard_dist = np.zeros_like(original_dist)\n",
    "    for i in range(prob.shape[0]):\n",
    "        ind_non_zero = np.where(original_dist[i, :] < 0.6)[0]\n",
    "        ind_images = [inv for inv in ind_non_zero if len(np.intersect1d(nn_k1[i], nn_k1[inv])) > 0]\n",
    "        for j in ind_images:\n",
    "            intersection = len(np.intersect1d(nn_k1[i], nn_k1[j]))\n",
    "            union = len(np.union1d(nn_k1[i], nn_k1[j]))\n",
    "            jaccard_dist[i, j] = 1 - intersection / union\n",
    "    \n",
    "    return 1 - (jaccard_dist * lambda_value + original_dist * (1 - lambda_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b52fe731b9948ec8a118f483fc2366c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/348M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded eva02_base_patch14_448.mim_in22k_ft_in22k_in1k | Feat: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ol1v3_7dwns5u\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ol1v3_7dwns5u\\.cache\\huggingface\\hub\\models--timm--eva02_base_patch14_448.mim_in22k_ft_in22k_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457457218ac648feb6a277550d946077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 13.7642 | LR: 1.95e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b614c10a3834f9eb9626c85e33b487c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 6.9714 | LR: 1.81e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df73e7084c74d29ac28ab3c37191a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 4.0637 | LR: 1.59e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e23a0f11964320b71637e92a2cb70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 2.7159 | LR: 1.31e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2a349c112642bca8db00e627abbbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 2.0453 | LR: 1.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5f1035d3ec405f93c4a04d1dce9082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 1.5801 | LR: 6.91e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078c091660854da99b4e3bf811301416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 1.2582 | LR: 4.12e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbfd85ba9b34ba0bc6cf1d9e2c7b3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 1.1076 | LR: 1.91e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080caaf69f9c47c99fef890f7e60dca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.9474 | LR: 4.89e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b7aa67237f4aae84d0028cfbeb9bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.8589 | LR: 0.00e+00\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING\n",
    "# =============================================================================\n",
    "train_loader = DataLoader(\n",
    "    JaguarDataset(train_df, CFG.train_dir, train_transform),\n",
    "    batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "model = JaguarModel().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(pbar):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            loss = criterion(model(imgs, labels), labels) / CFG.grad_accum\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % CFG.grad_accum == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * CFG.grad_accum\n",
    "        pbar.set_postfix({'loss': f'{loss.item() * CFG.grad_accum:.4f}'})\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'best_model.pth')\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for 371 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee23d8545f6b4429a2b4cff3e65ecf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Query Expansion...\n",
      "Applying Re-ranking...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INFERENCE\n",
    "# =============================================================================\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "unique_images = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
    "test_loader = DataLoader(\n",
    "    JaguarDataset(pd.DataFrame({'filename': unique_images}), CFG.test_dir, test_transform, is_test=True),\n",
    "    batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers\n",
    ")\n",
    "\n",
    "print(f\"Extracting embeddings for {len(unique_images)} images...\")\n",
    "feats, names = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, fnames in tqdm(test_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        f1 = model(imgs)\n",
    "        if CFG.use_tta:\n",
    "            f2 = model(torch.flip(imgs, [3]))\n",
    "            f1 = (f1 + f2) / 2\n",
    "        feats.append(F.normalize(f1, dim=1).cpu())\n",
    "        names.extend(fnames)\n",
    "\n",
    "emb = torch.cat(feats, dim=0).numpy()\n",
    "img_map = {n: i for i, n in enumerate(names)}\n",
    "\n",
    "if CFG.use_qe:\n",
    "    emb = query_expansion(emb)\n",
    "\n",
    "sim_matrix = emb @ emb.T\n",
    "\n",
    "if CFG.use_rerank:\n",
    "    sim_matrix = k_reciprocal_rerank(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b428d17a514e3b94f0247dd5d34e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved | Mean: 0.3411\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SUBMISSION\n",
    "# =============================================================================\n",
    "print(\"Computing similarities...\")\n",
    "preds = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    s = sim_matrix[img_map[row['query_image']], img_map[row['gallery_image']]]\n",
    "    preds.append(max(0.0, min(1.0, s)))\n",
    "\n",
    "submission = pd.DataFrame({'row_id': test_df['row_id'], 'similarity': preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Saved | Mean: {np.mean(preds):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
