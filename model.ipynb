{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaguar Re-Identification\n",
    "\n",
    "## Score: .864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIG\n",
    "# =============================================================================\n",
    "class CFG:\n",
    "    data_dir = Path('jaguar-re-id')\n",
    "    train_csv = data_dir / 'train.csv'\n",
    "    test_csv = data_dir / 'test.csv'\n",
    "    train_dir = data_dir / 'train' / 'train'\n",
    "    test_dir = data_dir / 'test' / 'test'\n",
    "    \n",
    "    backbone = 'convnext_base.fb_in22k_ft_in1k'\n",
    "    image_size = 384\n",
    "    num_classes = 31\n",
    "    \n",
    "    epochs = 20\n",
    "    batch_size = 16\n",
    "    lr = 2e-4\n",
    "    weight_decay = 0.01\n",
    "    warmup_epochs = 2\n",
    "    \n",
    "    arcface_s = 30.0\n",
    "    arcface_m = 0.5\n",
    "    label_smoothing = 0.1\n",
    "    \n",
    "    samples_per_class = 60\n",
    "    \n",
    "    use_tta = True\n",
    "    use_qe = True\n",
    "    use_rerank = True\n",
    "    \n",
    "    num_workers = 0\n",
    "    mixed_precision = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1895 | Test pairs: 137270\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA\n",
    "# =============================================================================\n",
    "train_df = pd.read_csv(CFG.train_csv)\n",
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Train: {len(train_df)} | Test pairs: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRANSFORMS\n",
    "# =============================================================================\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=CFG.image_size),\n",
    "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Affine(scale=(0.85, 1.15), rotate=(-15, 15), shear=(-10, 10), p=0.5),\n",
    "        A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10, 50), p=0.2),\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_test_transforms(flip=False):\n",
    "    t = [\n",
    "        A.LongestMaxSize(max_size=CFG.image_size),\n",
    "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
    "    ]\n",
    "    if flip:\n",
    "        t.append(A.HorizontalFlip(p=1.0))\n",
    "    t.extend([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    return A.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET & SAMPLER\n",
    "# =============================================================================\n",
    "class JaguarDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        unique_ids = sorted(df['ground_truth'].unique())\n",
    "        self.label_map = {name: i for i, name in enumerate(unique_ids)}\n",
    "        self.labels = [self.label_map[gt] for gt in df['ground_truth']]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = np.array(Image.open(self.img_dir / row['filename']).convert('RGB'))\n",
    "        img = self.transform(image=img)['image']\n",
    "        return img, torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "class JaguarTestDataset(Dataset):\n",
    "    def __init__(self, filenames, img_dir, transform):\n",
    "        self.filenames = filenames\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.filenames[idx]\n",
    "        img = np.array(Image.open(self.img_dir / fname).convert('RGB'))\n",
    "        img = self.transform(image=img)['image']\n",
    "        return img, fname\n",
    "\n",
    "\n",
    "class BalancedSampler(Sampler):\n",
    "    def __init__(self, labels, samples_per_class):\n",
    "        self.labels = labels\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.class_indices = defaultdict(list)\n",
    "        for idx, label in enumerate(labels):\n",
    "            self.class_indices[label].append(idx)\n",
    "        self.num_classes = len(self.class_indices)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        for label in self.class_indices:\n",
    "            class_idx = self.class_indices[label]\n",
    "            if len(class_idx) >= self.samples_per_class:\n",
    "                sampled = random.sample(class_idx, self.samples_per_class)\n",
    "            else:\n",
    "                sampled = random.choices(class_idx, k=self.samples_per_class)\n",
    "            indices.extend(sampled)\n",
    "        random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_classes * self.samples_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL\n",
    "# =============================================================================\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1.0 / self.p)\n",
    "\n",
    "\n",
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, s=30.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s, self.m = s, m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        theta = torch.acos(cosine.clamp(-1 + 1e-7, 1 - 1e-7))\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "        one_hot = F.one_hot(labels, num_classes=cosine.size(1)).float()\n",
    "        output = cosine * (1 - one_hot) + target_logits * one_hot\n",
    "        return output * self.s\n",
    "\n",
    "\n",
    "class JaguarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(CFG.backbone, pretrained=True, num_classes=0)\n",
    "        self.feat_dim = self.backbone.num_features\n",
    "        self.gem = GeM()\n",
    "        self.bn = nn.BatchNorm1d(self.feat_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.arcface = ArcFaceLoss(self.feat_dim, CFG.num_classes, CFG.arcface_s, CFG.arcface_m)\n",
    "        print(f\"Loaded {CFG.backbone} | Features: {self.feat_dim}\")\n",
    "    \n",
    "    def extract(self, x):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        if features.dim() == 3:\n",
    "            B, N, C = features.shape\n",
    "            H = W = int(math.sqrt(N))\n",
    "            features = features.permute(0, 2, 1).reshape(B, C, H, W)\n",
    "        emb = self.gem(features).flatten(1)\n",
    "        emb = self.bn(emb)\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, x, labels=None):\n",
    "        emb = self.extract(x)\n",
    "        if labels is not None:\n",
    "            emb = self.dropout(emb)\n",
    "            return self.arcface(emb, labels)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# POST-PROCESSING\n",
    "# =============================================================================\n",
    "def query_expansion(emb, top_k=3):\n",
    "    print(\"Applying Query Expansion...\")\n",
    "    sims = emb @ emb.T\n",
    "    indices = np.argsort(-sims, axis=1)[:, :top_k]\n",
    "    new_emb = np.zeros_like(emb)\n",
    "    for i in range(len(emb)):\n",
    "        new_emb[i] = np.mean(emb[indices[i]], axis=0)\n",
    "    return new_emb / np.linalg.norm(new_emb, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def k_reciprocal_rerank(prob, k1=20, k2=6, lambda_value=0.3):\n",
    "    print(\"Applying Re-ranking...\")\n",
    "    q_g_dist = 1 - prob\n",
    "    original_dist = q_g_dist.copy()\n",
    "    initial_rank = np.argsort(original_dist, axis=1)\n",
    "    \n",
    "    nn_k1 = []\n",
    "    for i in range(prob.shape[0]):\n",
    "        forward_k1 = initial_rank[i, :k1+1]\n",
    "        backward_k1 = initial_rank[forward_k1, :k1+1]\n",
    "        fi = np.where(backward_k1 == i)[0]\n",
    "        nn_k1.append(forward_k1[fi])\n",
    "    \n",
    "    jaccard_dist = np.zeros_like(original_dist)\n",
    "    for i in range(prob.shape[0]):\n",
    "        ind_non_zero = np.where(original_dist[i, :] < 0.6)[0]\n",
    "        ind_images = [inv for inv in ind_non_zero if len(np.intersect1d(nn_k1[i], nn_k1[inv])) > 0]\n",
    "        for j in ind_images:\n",
    "            intersection = len(np.intersect1d(nn_k1[i], nn_k1[j]))\n",
    "            union = len(np.union1d(nn_k1[i], nn_k1[j]))\n",
    "            jaccard_dist[i, j] = 1 - intersection / union\n",
    "    \n",
    "    return 1 - (jaccard_dist * lambda_value + original_dist * (1 - lambda_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Temp\\ipykernel_16532\\884487134.py:11: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10, 50), p=0.2),\n",
      "C:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Temp\\ipykernel_16532\\884487134.py:12: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded convnext_base.fb_in22k_ft_in1k | Features: 1024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72caf83ab6a9450da279daf952a2c426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ol1v3_7dwns5u\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 15.6927 | LR: 1.05e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8bbb2ebc5148e3bce48efa145108f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 8.8783 | LR: 2.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8e1425d0c94c339629557e183da2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 4.0460 | LR: 1.98e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b5502d05864864a48b41414ba029d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 2.4877 | LR: 1.94e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d36fc8245c04b13b327e94de0671dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 1.8264 | LR: 1.87e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff9d92614d9454e938940426ea66b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 1.6712 | LR: 1.77e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18906fae54e44c8599749e236c6e2146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 1.3255 | LR: 1.64e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4db8f962c44be3a63415885f16781b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 1.1233 | LR: 1.50e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd648b162a004201b683fb78612e9242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.9826 | LR: 1.34e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2276e6a52d6741d7803ff6049aeea44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.9337 | LR: 1.17e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb159f3eb1d04e3ebde3e2695ac984fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.8920 | LR: 9.99e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542650807c0d4ddcb51ce2d0646d1bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 0.8613 | LR: 8.25e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3235283f23fa4d008c3f9e6fa7adb0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 0.8394 | LR: 6.57e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da7de1dbfe744eb9c942d5e0e274e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 0.7740 | LR: 4.99e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678f4630a55f44768538b5cb2934ec65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.7761 | LR: 3.56e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1645c9435c9439e8b45bb7ce6e0b267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 0.7615 | LR: 2.33e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452356bca963462fb51596d6bc658dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 0.7365 | LR: 1.33e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8339123fdce44079a9831f327ba133be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 0.7336 | LR: 5.98e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19d037298a643d0a6943acc2056e36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 0.7264 | LR: 1.49e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf3d4f14b33469abd537733f3698781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.7409 | LR: 9.11e-10\n",
      "Training complete | Best loss: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING\n",
    "# =============================================================================\n",
    "train_dataset = JaguarDataset(train_df, CFG.train_dir, get_train_transforms())\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    sampler=BalancedSampler(train_dataset.labels, CFG.samples_per_class),\n",
    "    num_workers=CFG.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "model = JaguarModel().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=CFG.lr, epochs=CFG.epochs, steps_per_epoch=len(train_loader),\n",
    "    pct_start=CFG.warmup_epochs/CFG.epochs\n",
    ")\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing)\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(CFG.epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
    "    \n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            logits = model(imgs, labels)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print(f\"Training complete | Best loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for 371 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7f4332cda94166ae8ad6011109479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4867cae4a3e4267b32da4706bf25547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INFERENCE\n",
    "# =============================================================================\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "unique_images = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
    "print(f\"Extracting embeddings for {len(unique_images)} images...\")\n",
    "\n",
    "def extract_embeddings(transform):\n",
    "    loader = DataLoader(\n",
    "        JaguarTestDataset(unique_images, CFG.test_dir, transform),\n",
    "        batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers\n",
    "    )\n",
    "    feats, names = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, fnames in tqdm(loader, leave=False):\n",
    "            emb = model(imgs.to(device))\n",
    "            feats.append(F.normalize(emb, dim=1).cpu())\n",
    "            names.extend(fnames)\n",
    "    return torch.cat(feats, dim=0), names\n",
    "\n",
    "emb1, names = extract_embeddings(get_test_transforms(flip=False))\n",
    "if CFG.use_tta:\n",
    "    emb2, _ = extract_embeddings(get_test_transforms(flip=True))\n",
    "    emb = F.normalize((emb1 + emb2) / 2, dim=1).numpy()\n",
    "else:\n",
    "    emb = emb1.numpy()\n",
    "\n",
    "img_map = {n: i for i, n in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Query Expansion...\n",
      "Applying Re-ranking...\n",
      "Computing similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3564d177e5a4ef094c8d3e7575ad39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv | Mean sim: 0.3098\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# POST-PROCESSING & SUBMISSION\n",
    "# =============================================================================\n",
    "if CFG.use_qe:\n",
    "    emb = query_expansion(emb)\n",
    "\n",
    "sim_matrix = emb @ emb.T\n",
    "\n",
    "if CFG.use_rerank:\n",
    "    sim_matrix = k_reciprocal_rerank(sim_matrix)\n",
    "\n",
    "print(\"Computing similarities...\")\n",
    "preds = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    s = sim_matrix[img_map[row['query_image']], img_map[row['gallery_image']]]\n",
    "    preds.append(float(np.clip(s, 0, 1)))\n",
    "\n",
    "submission = pd.DataFrame({'row_id': test_df['row_id'], 'similarity': preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Saved submission.csv | Mean sim: {np.mean(preds):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
