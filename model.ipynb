{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jaguar Re-Identification\n",
        "\n",
        "## Score: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def seed_everything(seed=80085):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIG\n",
        "# =============================================================================\n",
        "class CFG:\n",
        "    data_dir = Path('jaguar-re-id')\n",
        "    train_csv = data_dir / 'train.csv'\n",
        "    test_csv = data_dir / 'test.csv'\n",
        "    train_dir = data_dir / 'train' / 'train'\n",
        "    test_dir = data_dir / 'test' / 'test'\n",
        "    \n",
        "    backbone = 'convnext_base.fb_in22k_ft_in1k'\n",
        "    image_size = 384\n",
        "    num_classes = 31\n",
        "    \n",
        "    epochs = 30\n",
        "    batch_size = 16\n",
        "    lr = 1e-4\n",
        "    weight_decay = 0.01\n",
        "    warmup_epochs = 2\n",
        "    \n",
        "    arcface_s = 30.0\n",
        "    arcface_m = 0.5\n",
        "    \n",
        "    use_tta = True\n",
        "    num_workers = 0\n",
        "    mixed_precision = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1895 | Test pairs: 137270 | Classes: 31\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DATA\n",
        "# =============================================================================\n",
        "train_df = pd.read_csv(CFG.train_csv)\n",
        "test_df = pd.read_csv(CFG.test_csv)\n",
        "\n",
        "print(f\"Train: {len(train_df)} | Test pairs: {len(test_df)} | Classes: {train_df['ground_truth'].nunique()}\")\n",
        "\n",
        "class_counts = train_df['ground_truth'].value_counts()\n",
        "plt.figure(figsize=(14, 4))\n",
        "class_counts.plot(kind='bar')\n",
        "plt.title('Images per Jaguar')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRANSFORMS\n",
        "# =============================================================================\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "        A.LongestMaxSize(max_size=CFG.image_size),\n",
        "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Affine(scale=(0.85, 1.15), rotate=(-15, 15), shear=(-10, 10), p=0.5),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "        A.GaussNoise(std_range=(0.01, 0.05), p=0.2),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_test_transforms(flip=False):\n",
        "    transforms = [\n",
        "        A.LongestMaxSize(max_size=CFG.image_size),\n",
        "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
        "    ]\n",
        "    if flip:\n",
        "        transforms.append(A.HorizontalFlip(p=1.0))\n",
        "    transforms.extend([\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    return A.Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET\n",
        "# =============================================================================\n",
        "class JaguarDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        unique_labels = sorted(df['ground_truth'].unique())\n",
        "        self.label_encoder = {name: idx for idx, name in enumerate(unique_labels)}\n",
        "        self.labels = np.array([self.label_encoder[gt] for gt in df['ground_truth']])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = np.array(Image.open(self.img_dir / row['filename']).convert('RGB'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "\n",
        "class JaguarTestDataset(Dataset):\n",
        "    def __init__(self, image_files, img_dir, transform=None):\n",
        "        self.image_files = image_files\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.image_files[idx]\n",
        "        image = np.array(Image.open(self.img_dir / filename).convert('RGB'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image, filename\n",
        "\n",
        "\n",
        "class BalancedSampler(Sampler):\n",
        "    def __init__(self, labels, samples_per_class=80):\n",
        "        self.class_indices = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            if label not in self.class_indices:\n",
        "                self.class_indices[label] = []\n",
        "            self.class_indices[label].append(idx)\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.total_samples = len(self.class_indices) * self.samples_per_class\n",
        "        \n",
        "    def __iter__(self):\n",
        "        indices = []\n",
        "        for cls_indices in self.class_indices.values():\n",
        "            selected = np.random.choice(cls_indices, self.samples_per_class, replace=len(cls_indices) < self.samples_per_class)\n",
        "            indices.extend(selected)\n",
        "        np.random.shuffle(indices)\n",
        "        return iter(indices)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.total_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODEL\n",
        "# =============================================================================\n",
        "class ArcFaceLoss(nn.Module):\n",
        "    def __init__(self, num_classes, embedding_dim, s=30.0, m=0.5):\n",
        "        super().__init__()\n",
        "        self.s, self.m = s, m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, embedding_dim))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        self.cos_m, self.sin_m = math.cos(m), math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "        \n",
        "    def forward(self, embeddings, labels):\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "        weight = F.normalize(self.weight, p=2, dim=1)\n",
        "        cosine = F.linear(embeddings, weight)\n",
        "        sine = torch.sqrt(1.0 - torch.clamp(cosine ** 2, 0, 1))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = torch.zeros_like(cosine).scatter_(1, labels.view(-1, 1).long(), 1)\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        return F.cross_entropy(output * self.s, labels)\n",
        "\n",
        "\n",
        "class JaguarModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(CFG.backbone, pretrained=True, num_classes=0)\n",
        "        self.embedding_dim = self.backbone.num_features\n",
        "        self.arcface = ArcFaceLoss(CFG.num_classes, self.embedding_dim, CFG.arcface_s, CFG.arcface_m)\n",
        "        print(f\"Loaded {CFG.backbone} | Embedding: {self.embedding_dim} | Params: {sum(p.numel() for p in self.parameters()):,}\")\n",
        "        \n",
        "    def forward(self, x, labels=None):\n",
        "        emb = F.normalize(self.backbone(x), p=2, dim=1)\n",
        "        if labels is not None:\n",
        "            return emb, self.arcface(emb, labels)\n",
        "        return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded hf-hub:BVRA/MegaDescriptor-L-384 | Embedding: 1536 | Params: 195,246,132\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Temp\\ipykernel_55740\\3029805447.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if CFG.mixed_precision else None\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4027e37146343f4ae5666dcda256fdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/40:   0%|          | 0/155 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Temp\\ipykernel_55740\\3029805447.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ol1v3_7dwns5u\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CFG.mixed_precision:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         _, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     scaler.scale(loss).backward()\n\u001b[32m     28\u001b[39m     scaler.step(optimizer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mJaguarModel.forward\u001b[39m\u001b[34m(self, x, labels)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, labels=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     emb = F.normalize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m emb, \u001b[38;5;28mself\u001b[39m.arcface(emb, labels)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:687\u001b[39m, in \u001b[36mSwinTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.forward_head(x)\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:679\u001b[39m, in \u001b[36mSwinTransformer.forward_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    678\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.patch_embed(x)\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm(x)\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:445\u001b[39m, in \u001b[36mSwinTransformerStage.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    443\u001b[39m     x = checkpoint_seq(\u001b[38;5;28mself\u001b[39m.blocks, x)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:324\u001b[39m, in \u001b[36mSwinTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    323\u001b[39m     B, H, W, C = x.shape\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.drop_path1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    325\u001b[39m     x = x.reshape(B, -\u001b[32m1\u001b[39m, C)\n\u001b[32m    326\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.drop_path2(\u001b[38;5;28mself\u001b[39m.mlp(\u001b[38;5;28mself\u001b[39m.norm2(x)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:308\u001b[39m, in \u001b[36mSwinTransformerBlock._attn\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    305\u001b[39m x_windows = x_windows.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.window_area, C)  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# W-MSA/SW-MSA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m attn_windows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# merge windows\u001b[39;00m\n\u001b[32m    311\u001b[39m attn_windows = attn_windows.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.window_size[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.window_size[\u001b[32m1\u001b[39m], C)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:173\u001b[39m, in \u001b[36mWindowAttention.forward\u001b[39m\u001b[34m(self, x, mask)\u001b[39m\n\u001b[32m    171\u001b[39m q = q * \u001b[38;5;28mself\u001b[39m.scale\n\u001b[32m    172\u001b[39m attn = q @ k.transpose(-\u001b[32m2\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m attn = attn + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_rel_pos_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    175\u001b[39m     num_win = mask.shape[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\swin_transformer.py:143\u001b[39m, in \u001b[36mWindowAttention._get_rel_pos_bias\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m     trunc_normal_(\u001b[38;5;28mself\u001b[39m.relative_position_bias_table, std=\u001b[32m.02\u001b[39m)\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.softmax = nn.Softmax(dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_rel_pos_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> torch.Tensor:\n\u001b[32m    144\u001b[39m     relative_position_bias = \u001b[38;5;28mself\u001b[39m.relative_position_bias_table[\n\u001b[32m    145\u001b[39m         \u001b[38;5;28mself\u001b[39m.relative_position_index.view(-\u001b[32m1\u001b[39m)].view(\u001b[38;5;28mself\u001b[39m.window_area, \u001b[38;5;28mself\u001b[39m.window_area, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Wh*Ww,Wh*Ww,nH\u001b[39;00m\n\u001b[32m    146\u001b[39m     relative_position_bias = relative_position_bias.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).contiguous()  \u001b[38;5;66;03m# nH, Wh*Ww, Wh*Ww\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TRAINING\n",
        "# =============================================================================\n",
        "train_dataset = JaguarDataset(train_df, CFG.train_dir, transform=get_train_transforms())\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, sampler=BalancedSampler(train_dataset.labels), \n",
        "                          num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "model = JaguarModel().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr, total_steps=len(train_loader) * CFG.epochs,\n",
        "                                                 pct_start=CFG.warmup_epochs / CFG.epochs)\n",
        "scaler = GradScaler() if CFG.mixed_precision else None\n",
        "\n",
        "best_loss = float('inf')\n",
        "for epoch in range(CFG.epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
        "    \n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if CFG.mixed_precision:\n",
        "            with autocast():\n",
        "                _, loss = model(images, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            _, loss = model(images, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "    \n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
        "    \n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saved best model\")\n",
        "\n",
        "print(f\"\\nTraining complete. Best loss: {best_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting embeddings for 371 test images...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96b91ba469c142859a0d8b1608c4862d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting:   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarities for 137,270 pairs...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c9cdef9b6bb4da9a704ef198621ba2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/137270 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Submission saved: submission.csv\n",
            "Rows: 137270 | Mean: 0.5110 | Std: 0.0973\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# INFERENCE\n",
        "# =============================================================================\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "unique_images = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
        "print(f\"Extracting embeddings for {len(unique_images)} test images...\")\n",
        "\n",
        "def extract_embeddings(transform):\n",
        "    dataset = JaguarTestDataset(unique_images, CFG.test_dir, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=CFG.num_workers)\n",
        "    emb_dict = {}\n",
        "    with torch.no_grad():\n",
        "        for images, filenames in tqdm(loader, desc='Extracting', leave=False):\n",
        "            emb = model(images.to(device))\n",
        "            for fname, e in zip(filenames, emb):\n",
        "                emb_dict[fname] = e.cpu().numpy()\n",
        "    return emb_dict\n",
        "\n",
        "if CFG.use_tta:\n",
        "    print(\"TTA enabled\")\n",
        "    emb_original = extract_embeddings(get_test_transforms(flip=False))\n",
        "    emb_flipped = extract_embeddings(get_test_transforms(flip=True))\n",
        "    \n",
        "    embeddings_dict = {}\n",
        "    for fname in unique_images:\n",
        "        avg_emb = (emb_original[fname] + emb_flipped[fname]) / 2\n",
        "        embeddings_dict[fname] = avg_emb / np.linalg.norm(avg_emb)\n",
        "else:\n",
        "    embeddings_dict = extract_embeddings(get_test_transforms(flip=False))\n",
        "\n",
        "print(\"Computing similarities...\")\n",
        "similarities = []\n",
        "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "    sim = np.dot(embeddings_dict[row['query_image']], embeddings_dict[row['gallery_image']])\n",
        "    similarities.append((sim + 1) / 2)\n",
        "\n",
        "submission = pd.DataFrame({'row_id': test_df['row_id'], 'similarity': similarities})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(f\"\\nSubmission saved: submission.csv\")\n",
        "print(f\"Rows: {len(submission)} | Mean: {submission['similarity'].mean():.4f} | Std: {submission['similarity'].std():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
