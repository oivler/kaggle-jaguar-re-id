{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jaguar Re-Identification\n",
        "\n",
        "## Score: .873"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIG â€” back to what worked (0.883): 224px, 12 epochs, single model, TTA only\n",
        "# =============================================================================\n",
        "class CFG:\n",
        "    data_dir = Path('jaguar-re-id')\n",
        "    train_csv = data_dir / 'train.csv'\n",
        "    test_csv = data_dir / 'test.csv'\n",
        "    train_dir = data_dir / 'train' / 'train'\n",
        "    test_dir = data_dir / 'test' / 'test'\n",
        "    \n",
        "    backbone = 'convnext_base.fb_in22k_ft_in1k'\n",
        "    image_size = 224\n",
        "    num_classes = 31\n",
        "    \n",
        "    epochs = 12\n",
        "    batch_size = 32\n",
        "    lr = 2e-4\n",
        "    weight_decay = 0.01\n",
        "    warmup_epochs = 2\n",
        "    \n",
        "    arcface_s = 30.0\n",
        "    arcface_m = 0.5\n",
        "    label_smoothing = 0.1\n",
        "    \n",
        "    samples_per_class = 60\n",
        "    \n",
        "    use_tta = True\n",
        "    use_multiscale_tta = False\n",
        "    use_qe = False\n",
        "    use_rerank = False\n",
        "    \n",
        "    train_seeds = [42]\n",
        "    \n",
        "    num_workers = 0\n",
        "    mixed_precision = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1895 | Test pairs: 137270\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DATA\n",
        "# =============================================================================\n",
        "train_df = pd.read_csv(CFG.train_csv)\n",
        "test_df = pd.read_csv(CFG.test_csv)\n",
        "print(f\"Train: {len(train_df)} | Test pairs: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRANSFORMS\n",
        "# =============================================================================\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "        A.LongestMaxSize(max_size=CFG.image_size),\n",
        "        A.PadIfNeeded(CFG.image_size, CFG.image_size, border_mode=0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Affine(scale=(0.9, 1.1), rotate=(-12, 12), shear=(-8, 8), p=0.5),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.08, p=0.5),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_test_transforms(flip=False, size=None):\n",
        "    sz = size if size is not None else CFG.image_size\n",
        "    t = [\n",
        "        A.LongestMaxSize(max_size=sz),\n",
        "        A.PadIfNeeded(sz, sz, border_mode=0),\n",
        "    ]\n",
        "    if flip:\n",
        "        t.append(A.HorizontalFlip(p=1.0))\n",
        "    t.extend([\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    return A.Compose(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET & SAMPLER\n",
        "# =============================================================================\n",
        "class JaguarDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        unique_ids = sorted(df['ground_truth'].unique())\n",
        "        self.label_map = {name: i for i, name in enumerate(unique_ids)}\n",
        "        self.labels = [self.label_map[gt] for gt in df['ground_truth']]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = np.array(Image.open(self.img_dir / row['filename']).convert('RGB'))\n",
        "        img = self.transform(image=img)['image']\n",
        "        return img, torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "\n",
        "class JaguarTestDataset(Dataset):\n",
        "    def __init__(self, filenames, img_dir, transform):\n",
        "        self.filenames = filenames\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.filenames[idx]\n",
        "        img = np.array(Image.open(self.img_dir / fname).convert('RGB'))\n",
        "        img = self.transform(image=img)['image']\n",
        "        return img, fname\n",
        "\n",
        "\n",
        "class BalancedSampler(Sampler):\n",
        "    def __init__(self, labels, samples_per_class):\n",
        "        self.labels = labels\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            self.class_indices[label].append(idx)\n",
        "        self.num_classes = len(self.class_indices)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        indices = []\n",
        "        for label in self.class_indices:\n",
        "            class_idx = self.class_indices[label]\n",
        "            if len(class_idx) >= self.samples_per_class:\n",
        "                sampled = random.sample(class_idx, self.samples_per_class)\n",
        "            else:\n",
        "                sampled = random.choices(class_idx, k=self.samples_per_class)\n",
        "            indices.extend(sampled)\n",
        "        random.shuffle(indices)\n",
        "        return iter(indices)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_classes * self.samples_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODEL\n",
        "# =============================================================================\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1.0 / self.p)\n",
        "\n",
        "\n",
        "class ArcFaceLoss(nn.Module):\n",
        "    def __init__(self, in_features, num_classes, s=30.0, m=0.5):\n",
        "        super().__init__()\n",
        "        self.s, self.m = s, m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "    \n",
        "    def forward(self, x, labels):\n",
        "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
        "        theta = torch.acos(cosine.clamp(-1 + 1e-7, 1 - 1e-7))\n",
        "        target_logits = torch.cos(theta + self.m)\n",
        "        one_hot = F.one_hot(labels, num_classes=cosine.size(1)).float()\n",
        "        output = cosine * (1 - one_hot) + target_logits * one_hot\n",
        "        return output * self.s\n",
        "\n",
        "\n",
        "class JaguarModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(CFG.backbone, pretrained=True, num_classes=0)\n",
        "        self.feat_dim = self.backbone.num_features\n",
        "        self.gem = GeM()\n",
        "        self.bn = nn.BatchNorm1d(self.feat_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.arcface = ArcFaceLoss(self.feat_dim, CFG.num_classes, CFG.arcface_s, CFG.arcface_m)\n",
        "        print(f\"Loaded {CFG.backbone} | Features: {self.feat_dim}\")\n",
        "    \n",
        "    def extract(self, x):\n",
        "        features = self.backbone.forward_features(x)\n",
        "        if features.dim() == 3:\n",
        "            B, N, C = features.shape\n",
        "            H = W = int(math.sqrt(N))\n",
        "            features = features.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        emb = self.gem(features).flatten(1)\n",
        "        emb = self.bn(emb)\n",
        "        return emb\n",
        "    \n",
        "    def forward(self, x, labels=None):\n",
        "        emb = self.extract(x)\n",
        "        if labels is not None:\n",
        "            emb = self.dropout(emb)\n",
        "            return self.arcface(emb, labels)\n",
        "        return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# POST-PROCESSING\n",
        "# =============================================================================\n",
        "def query_expansion(emb, top_k=None):\n",
        "    top_k = top_k if top_k is not None else getattr(CFG, 'qe_top_k', 3)\n",
        "    print(\"Applying Query Expansion...\")\n",
        "    sims = emb @ emb.T\n",
        "    indices = np.argsort(-sims, axis=1)[:, :top_k]\n",
        "    new_emb = np.zeros_like(emb)\n",
        "    for i in range(len(emb)):\n",
        "        new_emb[i] = np.mean(emb[indices[i]], axis=0)\n",
        "    return new_emb / np.linalg.norm(new_emb, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def k_reciprocal_rerank(prob, k1=20, k2=6, lambda_value=None):\n",
        "    lambda_value = lambda_value if lambda_value is not None else getattr(CFG, 'rerank_lambda', 0.3)\n",
        "    print(\"Applying Re-ranking...\")\n",
        "    q_g_dist = 1 - prob\n",
        "    original_dist = q_g_dist.copy()\n",
        "    initial_rank = np.argsort(original_dist, axis=1)\n",
        "    \n",
        "    nn_k1 = []\n",
        "    for i in range(prob.shape[0]):\n",
        "        forward_k1 = initial_rank[i, :k1+1]\n",
        "        backward_k1 = initial_rank[forward_k1, :k1+1]\n",
        "        fi = np.where(backward_k1 == i)[0]\n",
        "        nn_k1.append(forward_k1[fi])\n",
        "    \n",
        "    jaccard_dist = np.zeros_like(original_dist)\n",
        "    for i in range(prob.shape[0]):\n",
        "        ind_non_zero = np.where(original_dist[i, :] < 0.6)[0]\n",
        "        ind_images = [inv for inv in ind_non_zero if len(np.intersect1d(nn_k1[i], nn_k1[inv])) > 0]\n",
        "        for j in ind_images:\n",
        "            intersection = len(np.intersect1d(nn_k1[i], nn_k1[j]))\n",
        "            union = len(np.union1d(nn_k1[i], nn_k1[j]))\n",
        "            jaccard_dist[i, j] = 1 - intersection / union\n",
        "    \n",
        "    return 1 - (jaccard_dist * lambda_value + original_dist * (1 - lambda_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded convnext_base.fb_in22k_ft_in1k | Features: 1024\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41e00c6ad82347b3989f89d267abee87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 1/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ol1v3_7dwns5u\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 15.5181 | LR: 1.05e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "322161ba2ce845d18f0009570ba48a14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 2/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 8.1121 | LR: 2.00e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b0b26856ee74e4b9c3305f77276ddd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 3/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.9633 | LR: 1.95e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976bdf60e3e747cfa7eeff4a3273cb7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 4/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.7582 | LR: 1.81e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d615c9c2f5a474fb6ef255287be54b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 5/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.2240 | LR: 1.58e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cb33747d03742a382c02026899e18a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 6/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.0999 | LR: 1.30e-04\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "939cd5decff74fbba0d475fa0f7a1dc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 7/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 0.9149 | LR: 9.95e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d49b38120b204474836eaf1f79154b53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 8/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 0.8409 | LR: 6.86e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d3a65c66904fcda50053a488a1bbfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 9/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 0.8319 | LR: 4.08e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d7e68e7d5bf4c4faf3a99ac729d0347",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 10/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 0.7951 | LR: 1.88e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ab5f17af325402daf22b73bca20da6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 11/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 | Loss: 0.7616 | LR: 4.73e-06\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bce9fbb06f1484685332c150a6af8e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Seed 42 Epoch 12/12:   0%|          | 0/59 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 | Loss: 0.7639 | LR: 2.22e-09\n",
            "Run 1 (seed 42) complete | Best loss: 0.7616 | Saved best_model.pth\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TRAINING (two seeds by default for ensemble)\n",
        "# =============================================================================\n",
        "train_seeds = getattr(CFG, 'train_seeds', [42])\n",
        "for run_idx, seed in enumerate(train_seeds):\n",
        "    seed_everything(seed)\n",
        "    ckpt_name = 'best_model.pth' if run_idx == 0 else 'best_model_s2.pth'\n",
        "    train_dataset = JaguarDataset(train_df, CFG.train_dir, get_train_transforms())\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CFG.batch_size,\n",
        "        sampler=BalancedSampler(train_dataset.labels, CFG.samples_per_class),\n",
        "        num_workers=CFG.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    model = JaguarModel().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=CFG.lr, epochs=CFG.epochs, steps_per_epoch=len(train_loader),\n",
        "        pct_start=CFG.warmup_epochs/CFG.epochs\n",
        "    )\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing)\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(CFG.epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(train_loader, desc=f'Seed {seed} Epoch {epoch+1}/{CFG.epochs}')\n",
        "        for imgs, labels in pbar:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(imgs, labels)\n",
        "                loss = criterion(logits, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            torch.save(model.state_dict(), ckpt_name)\n",
        "    print(f\"Run {run_idx+1} (seed {seed}) complete | Best loss: {best_loss:.4f} | Saved {ckpt_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting embeddings for 371 images...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dbc69cc7f01435f8eabf0292bb34e5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "546a1902fbde4eeeb66c35298f26de3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble: loading second model...\n",
            "Loaded convnext_base.fb_in22k_ft_in1k | Features: 1024\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e45c70169e7a4e8ba5d8450cfb531896",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58a438bc11154b0ca069cb0f2ad49dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# INFERENCE\n",
        "# =============================================================================\n",
        "unique_images = sorted(set(test_df['query_image']) | set(test_df['gallery_image']))\n",
        "print(f\"Extracting embeddings for {len(unique_images)} images...\")\n",
        "\n",
        "def extract_embeddings(transform, m):\n",
        "    loader = DataLoader(\n",
        "        JaguarTestDataset(unique_images, CFG.test_dir, transform),\n",
        "        batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers\n",
        "    )\n",
        "    feats, names = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, fnames in tqdm(loader, leave=False):\n",
        "            emb = m(imgs.to(device))\n",
        "            feats.append(F.normalize(emb, dim=1).cpu())\n",
        "            names.extend(fnames)\n",
        "    return torch.cat(feats, dim=0), names\n",
        "\n",
        "def get_embeddings(m, size=None):\n",
        "    sz = size if size is not None else CFG.image_size\n",
        "    e1, names = extract_embeddings(get_test_transforms(flip=False, size=sz), m)\n",
        "    if CFG.use_tta:\n",
        "        e2, _ = extract_embeddings(get_test_transforms(flip=True, size=sz), m)\n",
        "        e = F.normalize((e1 + e2) / 2, dim=1)\n",
        "    else:\n",
        "        e = e1\n",
        "    return e.numpy(), names\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "if getattr(CFG, 'use_multiscale_tta', False) and getattr(CFG, 'multiscale_sizes', None):\n",
        "    embs = []\n",
        "    for sz in CFG.multiscale_sizes:\n",
        "        e, names = get_embeddings(model, size=sz)\n",
        "        embs.append(e)\n",
        "    emb = np.stack(embs).mean(axis=0)\n",
        "    emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
        "else:\n",
        "    emb, names = get_embeddings(model)\n",
        "\n",
        "if Path('best_model_s2.pth').exists():\n",
        "    print(\"Ensemble: loading second model...\")\n",
        "    model2 = JaguarModel().to(device)\n",
        "    model2.load_state_dict(torch.load('best_model_s2.pth'))\n",
        "    model2.eval()\n",
        "    if getattr(CFG, 'use_multiscale_tta', False) and getattr(CFG, 'multiscale_sizes', None):\n",
        "        embs2 = [get_embeddings(model2, size=sz)[0] for sz in CFG.multiscale_sizes]\n",
        "        emb2 = np.stack(embs2).mean(axis=0)\n",
        "        emb2 = emb2 / np.linalg.norm(emb2, axis=1, keepdims=True)\n",
        "    else:\n",
        "        emb2, _ = get_embeddings(model2)\n",
        "    emb = (emb + emb2) / 2\n",
        "    emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
        "\n",
        "img_map = {n: i for i, n in enumerate(names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarities...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0ff4d8945f427b9e905d2cbf269b79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/137270 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved submission.csv | Mean sim: 0.0580\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# POST-PROCESSING & SUBMISSION\n",
        "# =============================================================================\n",
        "if CFG.use_qe:\n",
        "    emb = query_expansion(emb)\n",
        "\n",
        "sim_matrix = emb @ emb.T\n",
        "\n",
        "if CFG.use_rerank:\n",
        "    sim_matrix = k_reciprocal_rerank(sim_matrix)\n",
        "\n",
        "print(\"Computing similarities...\")\n",
        "preds = []\n",
        "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "    s = sim_matrix[img_map[row['query_image']], img_map[row['gallery_image']]]\n",
        "    preds.append(float(np.clip(s, 0, 1)))\n",
        "\n",
        "submission = pd.DataFrame({'row_id': test_df['row_id'], 'similarity': preds})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(f\"Saved submission.csv | Mean sim: {np.mean(preds):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
